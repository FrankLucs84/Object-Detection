# ğŸ” DETR - DEtection TRansformer: Architettura e Funzionamento

## ğŸ“– Introduzione

**DETR (DEtection TRansformer)** Ã¨ un modello per lâ€™object detection introdotto da Facebook AI Research (FAIR) nel 2020. Ãˆ il primo framework **end-to-end** che utilizza lâ€™architettura **Transformer**, tipica del NLP, per la rilevazione degli oggetti allâ€™interno di immagini.

ğŸ“š *Riferimento principale*:  
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., & Zagoruyko, S. (2020).  
*End-to-End Object Detection with Transformers*. arXiv:2005.12872.  
<https://arxiv.org/abs/2005.12872>

---

## ğŸ§  Idea chiave

DETR riformula il problema del rilevamento oggetti come una **trasduzione diretta da immagine a sequenza di oggetti**:  
> â€œData unâ€™immagine, produce direttamente un set di box con classi, senza alcuna euristica come anchor box o non-max suppression.â€

---

## âš™ï¸ Architettura di DETR

### 1. ğŸ” Feature Extractor (CNN Backbone)
- Solitamente una **ResNet-50 o ResNet-101**.
- Estrae una **mappa di caratteristiche** (feature map) dallâ€™immagine.

### 2. ğŸ”„ Transformer Encoder-Decoder
- **Encoder**: codifica le feature globalmente usando self-attention.
- **Decoder**: riceve un numero fisso di **query vettoriali (es. 100)**, ciascuna delle quali rappresenta una potenziale predizione oggetto.

### 3. ğŸ¯ Prediction Heads
- Ogni output del decoder Ã¨ passato a:
  - Un **MLP per la bounding box** (`[cx, cy, w, h]`).
  - Una **softmax per la classificazione**.

---

## ğŸ”¬ Dettagli chiave del funzionamento

- Le **object queries** sono **parametri appresi** che "cercano" gli oggetti nella scena.
- Lâ€™**output Ã¨ una sequenza di predizioni** con punteggio di confidenza e coordinate spaziali.
- Si utilizza un algoritmo di **Hungarian Matching** per associare predizioni e oggetti reali nel calcolo della loss.
- La loss totale include:
  - **Classification loss** (Cross-Entropy).
  - **Bounding box loss** (L1 + GIoU loss).

---

## ğŸ§ª Pipeline di elaborazione

1. **Input immagine** â†’ CNN (es. ResNet) â†’ Feature Map.
2. **Feature Map** â†’ Linearizzata + Positional Encoding â†’ Transformer Encoder.
3. **Decoder** + Query vettoriali â†’ Predizioni (classi + box).
4. **Post-processing**: Matching predizione-veritÃ  a terra via Hungarian Algorithm.

---

## ğŸ§¾ Caratteristiche principali

| Caratteristica                 | Dettaglio                                                       |
|-------------------------------|------------------------------------------------------------------|
| Architettura                  | Transformer Encoder-Decoder                                      |
| Componente CNN                | Solo per lâ€™estrazione iniziale delle feature (es. ResNet)       |
| Rimozione NMS                 | âœ… Eliminato (uso di Hungarian Matching)                         |
| End-to-End                    | âœ… Nessun bisogno di euristiche manuali                          |
| Numero di predizioni          | Fisso (es. 100 oggetti per immagine, alcuni possono essere "vuoti") |
| InterpretabilitÃ               | âœ… Attention maps interpretabili                                 |
| Convergenza                   | âŒ Lenta (necessita training piÃ¹ lungo)                          |

---

## ğŸ“‰ Limiti noti

- **Addestramento lento**: richiede piÃ¹ epoche rispetto a modelli classici.
- **Prestazioni iniziali inferiori su oggetti piccoli** (risolto in parte con *Deformable DETR*).
- **Inferenza piÃ¹ pesante** rispetto a modelli lightweight.

---

## ğŸš€ Evoluzioni di DETR

- **Deformable DETR**: introduce *multi-scale attention* e *sparse attention*, migliora su oggetti piccoli.
- **Conditional DETR**: migliora la stabilitÃ  delle predizioni.
- **DETR-2**: ottimizzazioni nella velocitÃ  e accuratezza, convergenza piÃ¹ rapida.

---

## ğŸ“š Altri riferimenti

- Zhu, X. et al. (2021). *Deformable DETR: Deformable Transformers for End-to-End Object Detection*.  
  <https://arxiv.org/abs/2010.04159>

- Hugging Face repository:  
  <https://huggingface.co/facebook/detr-resnet-50>

---

## ğŸ§© Conclusione

DETR rappresenta una svolta concettuale nellâ€™object detection, offrendo un approccio elegante e end-to-end che elimina molte complicazioni dei metodi tradizionali. Pur avendo dei limiti, ha aperto la strada a nuove architetture di visione artificiale basate sui Transformer.

